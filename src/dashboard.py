import gradio as gr
import cv2
import time
import pandas as pd
import threading
from PIL import Image
from agri_agent import AgriAgent
from ui_utils import SmartHUD

# --- 1. æ¨¡åž‹è·¯å¾„ ---
MODEL_PATH='/root/autodl-tmp/models/OpenBMB/MiniCPM-Llama3-V-2_5'
VIDEO_PATH = 'demo_video.mp4'
THINK_INTERVAL = 5

# --- å…¨å±€å˜é‡ ---
agent = None
hud = None
is_running = False

mock_sensors = {
    "battery": 98,
    "speed": 0.0,
    "lat": 34.0522,
    "lon": 118.2437
}

# --- æ–°å¢žå…¨å±€é”å’Œå…±äº«æ•°æ® ---
data_lock = threading.Lock()
# ç”¨äºŽå­˜å‚¨æœ€æ–°çš„ AI å†³ç­–ç»“æžœ
latest_inference_result = {
    "diagnosis": "ç­‰å¾…æ•°æ®...",
    "cmd": "å¾…å‘½"
}

def load_system():
    global agent, hud
    if agent is None:
        try:
            print("æ­£åœ¨åˆå§‹åŒ– AI å¤§è„‘...")
            agent = AgriAgent(model_path=MODEL_PATH)
            agent.load_model() 
            hud = SmartHUD(font_path='SimHei.ttf')
            return "âœ… ç³»ç»Ÿå°±ç»ª (System Online)"
        except Exception as e:
            return f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}"
    return "ç³»ç»Ÿå·²åœ¨è¿è¡Œ (System Already Online)"



# --- åŽå°çº¿ç¨‹å‡½æ•°ï¼šä¸“é—¨è´Ÿè´£è´¹æ—¶çš„ AI è®¡ç®— ---
def run_ai_background(img_pil):
    global latest_inference_result, agent, mock_sensors
    
    # 1. è€—æ—¶çš„é¢„æµ‹è¿‡ç¨‹
    raw_result = agent.predict(img_pil)
    key = raw_result.strip().replace(".", "")
    
    cn_map = {"Healthy": "å¥åº·", "Disease": "ç—…å®³", "Pest": "è™«å®³", "Unknown": "æœªçŸ¥"}
    diagnosis = cn_map.get(key, key)
    
    # 2. å†³ç­–é€»è¾‘
    if "Healthy" in key:
        cmd = "å…¨é€Ÿå·¡èˆª"
        target_speed = 1.5 
    elif "Disease" in key or "Pest" in key:
        cmd = "åœè½¦/å–·æ´’"
        target_speed = 0.0
    else:
        cmd = "å‡é€Ÿè§‚å¯Ÿ"
        target_speed = 0.5
        
    # 3. å®‰å…¨åœ°æ›´æ–°å…±äº«æ•°æ® (åŠ é”)
    with data_lock:
        latest_inference_result["diagnosis"] = diagnosis
        latest_inference_result["cmd"] = cmd
        mock_sensors['speed'] = target_speed

def processing_loop():
    global is_running, mock_sensors, latest_inference_result
    
    if agent is None:
        yield None, "ä¼ æ„Ÿå™¨ç¦»çº¿", pd.DataFrame(), "âš ï¸ è¯·å…ˆç‚¹å‡» [1. åˆå§‹åŒ–ç³»ç»Ÿ]"
        return

    cap = cv2.VideoCapture(VIDEO_PATH)
    frame_count = 0
    logs = []
    
    # ä½¿ç”¨ try...finally ç¡®ä¿è§†é¢‘æµä¸€å®šä¼šè¢«å…³é—­
    try:
        while is_running and cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue
                
            frame_count += 1
            
            # --- å¼‚æ­¥è§¦å‘ AI (ä¸ç­‰å¾…ç»“æžœ) ---
            if frame_count % THINK_INTERVAL == 0 :
                img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                # å¯åŠ¨çº¿ç¨‹ï¼Œdaemon=True è¡¨ç¤ºä¸»ç¨‹åºé€€å‡ºæ—¶çº¿ç¨‹è‡ªåŠ¨ç»“æŸ
                threading.Thread(target=run_ai_background, args=(img_pil,), daemon=True).start()
            
            # --- è¯»å–æœ€æ–°çŠ¶æ€ (åŠ é”è¯»å–) ---
            with data_lock:
                current_diagnosis = latest_inference_result["diagnosis"]
                current_cmd = latest_inference_result["cmd"]
                
                # åªæœ‰å½“æœ‰æ–°ç»“æžœæˆ–å®šæœŸæ—¶æ›´æ–°æ—¥å¿—ï¼Œé˜²æ­¢æ—¥å¿—åˆ·æ–°å¤ªå¿«
                if frame_count % THINK_INTERVAL == 0 :
                     timestamp = time.strftime("%H:%M:%S")
                     logs.insert(0, [timestamp, frame_count, current_diagnosis, current_cmd])
                     if len(logs) > 10: logs.pop()

            # --- ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿ ---
            mock_sensors['battery'] -= 0.01 
            if mock_sensors['battery'] < 0: mock_sensors['battery'] = 100
            
            # --- ç»˜åˆ¶ HUD ---
            # æ³¨æ„ï¼šè¿™é‡Œçš„ state ä¸å†éœ€è¦æ˜¾ç¤º "æ€è€ƒä¸­"ï¼Œå› ä¸ºè§†é¢‘å¾ˆæµç•…
            hud_data = {
                'frame_id': frame_count,
                'state': 'AI ç›‘æµ‹ä¸­ (æµç•…æ¨¡å¼)', 
                'diagnosis': current_diagnosis,
                'advice': f"ç›®æ ‡é€Ÿåº¦: {mock_sensors['speed']} m/s",
                'cmd': current_cmd,
                'latency': 0
            }
            frame = hud.render_panel(frame, hud_data)
            out_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            status_text = (
                f"ðŸ”‹ ç”µæ± : {int(mock_sensors['battery'])}%\n"
                f"ðŸš€ é€Ÿåº¦: {mock_sensors['speed']} m/s\n"
                f"ðŸ“ åæ ‡: ({mock_sensors['lat']}, {mock_sensors['lon']})"
            )
            
            log_df = pd.DataFrame(logs, columns=["æ—¶é—´", "å¸§å·", "è¯†åˆ«ç»“æžœ", "æ‰§è¡ŒæŒ‡ä»¤"])
            
            yield out_frame, status_text, log_df, "ðŸŸ¢ æ­£åœ¨å·¡èˆª (Patrolling)"
            # time.sleep(0.003) # æŽ§åˆ¶å¸§çŽ‡

    finally:
        cap.release()
        yield None, "å·²åœæ­¢", pd.DataFrame(), "ðŸ”´ ä»»åŠ¡ç»“æŸ"
"""
def processing_loop():
    global is_running, mock_sensors
    
    if agent is None:
        # å¦‚æžœæ²¡åˆå§‹åŒ–ï¼Œç›´æŽ¥è¿”å›žç©º
        yield None, "ä¼ æ„Ÿå™¨ç¦»çº¿", pd.DataFrame(), "âš ï¸ è¯·å…ˆç‚¹å‡» [1. åˆå§‹åŒ–ç³»ç»Ÿ]"
        return

    cap = cv2.VideoCapture(VIDEO_PATH)
    frame_count = 0
    logs = []
    
    current_diagnosis = "ç­‰å¾…æ•°æ®..."
    current_cmd = "å¾…å‘½"
    
    while is_running and cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            continue
            
        frame_count += 1
        
        # AI æŽ¨ç†
        if frame_count % THINK_INTERVAL == 0:
            img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            raw_result = agent.predict(img_pil)
            key = raw_result.strip().replace(".", "")
            
            cn_map = {"Healthy": "å¥åº·", "Disease": "ç—…å®³", "Pest": "è™«å®³", "Unknown": "æœªçŸ¥"}
            current_diagnosis = cn_map.get(key, key)
            
            if "Healthy" in key:
                current_cmd = "å…¨é€Ÿå·¡èˆª"
                mock_sensors['speed'] = 1.5 
            elif "Disease" in key or "Pest" in key:
                current_cmd = "åœè½¦/å–·æ´’"
                mock_sensors['speed'] = 0.0
            else:
                current_cmd = "å‡é€Ÿè§‚å¯Ÿ"
                mock_sensors['speed'] = 0.5
                
            timestamp = time.strftime("%H:%M:%S")
            logs.insert(0, [timestamp, frame_count, current_diagnosis, current_cmd])
            if len(logs) > 10: logs.pop()

        # ä¼ æ„Ÿå™¨æ¨¡æ‹Ÿ
        mock_sensors['battery'] -= 0.01 
        if mock_sensors['battery'] < 0: mock_sensors['battery'] = 100
        
        # ç»˜åˆ¶ HUD
        hud_data = {
            'frame_id': frame_count,
            'state': 'AI æ‰˜ç®¡ä¸­' if frame_count % THINK_INTERVAL != 0 else 'æ€è€ƒä¸­...',
            'diagnosis': current_diagnosis,
            'advice': f"å½“å‰è½¦é€Ÿ: {mock_sensors['speed']} m/s",
            'cmd': current_cmd,
            'latency': 0
        }
        frame = hud.render_panel(frame, hud_data)
        out_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        status_text = (
            f"ðŸ”‹ ç”µæ± : {int(mock_sensors['battery'])}%\n"
            f"ðŸš€ é€Ÿåº¦: {mock_sensors['speed']} m/s\n"
            f"ðŸ“ åæ ‡: ({mock_sensors['lat']}, {mock_sensors['lon']})"
        )
        
        log_df = pd.DataFrame(logs, columns=["æ—¶é—´", "å¸§å·", "è¯†åˆ«ç»“æžœ", "æ‰§è¡ŒæŒ‡ä»¤"])
        
        yield out_frame, status_text, log_df, "ðŸŸ¢ æ­£åœ¨å·¡èˆª (Patrolling)"
        time.sleep(0.03)

    cap.release()
    yield None, "å·²åœæ­¢", pd.DataFrame(), "ðŸ”´ ä»»åŠ¡ç»“æŸ"
"""
# --- 2. ç”Ÿæˆå™¨è°ƒç”¨ ---
def start_patrol():
    global is_running
    is_running = True
    # å…³é”®ä¿®æ”¹ï¼šç›´æŽ¥æŠŠç”Ÿæˆå™¨çš„å€¼ä¸€ä¸ªä¸ª yield å‡ºæ¥
    for output in processing_loop():
        yield output

def stop_patrol():
    global is_running
    is_running = False
    return "ðŸ”´ åœæ­¢æŒ‡ä»¤å·²å‘é€"

with gr.Blocks(title="AgriAgent æŒ‡æŒ¥ä¸­å¿ƒ", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ðŸšœ AgriAgent æ™ºèƒ½å†œä¸šæœºå™¨äºº - è¿œç¨‹æŒ‡æŒ¥ä¸­å¿ƒ")
    
    with gr.Row():
        with gr.Column(scale=2):
            video_display = gr.Image(label="å®žæ—¶å›žä¼ ç”»é¢", type="numpy")
        
        with gr.Column(scale=1):
            system_status = gr.Textbox(label="ç³»ç»Ÿæ—¥å¿—", value="ç­‰å¾…åˆå§‹åŒ–...", interactive=False)
            sensor_display = gr.Textbox(label="ä¼ æ„Ÿå™¨é¥æµ‹", lines=3, interactive=False)
            
            init_btn = gr.Button("1. åˆå§‹åŒ–ç³»ç»Ÿ", variant="primary")
            start_btn = gr.Button("2. å¼€å§‹å·¡èˆª", variant="secondary")
            stop_btn = gr.Button("3. ç´§æ€¥åœæ­¢", variant="stop")

    gr.Markdown("### ðŸ“‹ AI è¯Šæ–­æ—¥å¿—")
    log_table = gr.Dataframe(headers=["æ—¶é—´", "å¸§å·", "è¯†åˆ«ç»“æžœ", "æ‰§è¡ŒæŒ‡ä»¤"], interactive=False)

    init_btn.click(load_system, inputs=[], outputs=[system_status])
    
    start_btn.click(
        start_patrol, 
        inputs=[], 
        outputs=[video_display, sensor_display, log_table, system_status]
    )
    stop_btn.click(stop_patrol, inputs=[], outputs=[system_status])

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=6006)